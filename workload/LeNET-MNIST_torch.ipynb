{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required libraries\n",
    "import torch\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import random\n",
    "import os\n",
    "import pickle\n",
    "import time\n",
    "from sklearn.utils import shuffle\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup TensorFlow\n",
    "EPOCHS = 10\n",
    "BATCH_SIZE = 128\n",
    "LEARNING_RATE = 0.01\n",
    "# Importing the MNIST dataset\n",
    "# Load the MNIST dataset\n",
    "data = np.load('./mnist.npz')\n",
    "X_train, y_train = torch.from_numpy(data['x_train']), torch.from_numpy(data['y_train'])\n",
    "X_test, y_test = torch.from_numpy(data['x_test']), torch.from_numpy(data['y_test'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the LeNet-5 architecture\n",
    "class LeNet5(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LeNet5, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1, 6, kernel_size=5)\n",
    "        self.conv2 = nn.Conv2d(6, 16, kernel_size=5)\n",
    "        self.fc1 = nn.Linear(16 * 4 * 4, 120)\n",
    "        self.fc2 = nn.Linear(120, 84)\n",
    "        self.fc3 = nn.Linear(84, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = nn.functional.relu(self.conv1(x))\n",
    "        x = nn.functional.avg_pool2d(x, 2)\n",
    "        x = nn.functional.relu(self.conv2(x))\n",
    "        x = nn.functional.avg_pool2d(x, 2)\n",
    "        x = x.view(-1, 16 * 4 * 4)\n",
    "        x = nn.functional.relu(self.fc1(x))\n",
    "        x = nn.functional.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Test Loss: 0.0023, Accuracy: 91.13%\n",
      "Epoch 2/10, Test Loss: 0.0013, Accuracy: 94.96%\n",
      "Epoch 3/10, Test Loss: 0.0009, Accuracy: 96.40%\n",
      "Epoch 4/10, Test Loss: 0.0007, Accuracy: 97.08%\n",
      "Epoch 5/10, Test Loss: 0.0006, Accuracy: 97.47%\n",
      "Epoch 6/10, Test Loss: 0.0006, Accuracy: 97.34%\n",
      "Epoch 7/10, Test Loss: 0.0006, Accuracy: 97.52%\n",
      "Epoch 8/10, Test Loss: 0.0005, Accuracy: 98.09%\n",
      "Epoch 9/10, Test Loss: 0.0004, Accuracy: 98.43%\n",
      "Epoch 10/10, Test Loss: 0.0004, Accuracy: 98.48%\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "X_train = X_train.reshape(-1, 1, 28, 28)/255\n",
    "batch_size = 128\n",
    "train_dataset = TensorDataset(X_train.float(), y_train)\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n",
    "#test_dataset\n",
    "X_test = X_test.reshape(-1, 1, 28, 28)/255\n",
    "test_dataset = TensorDataset(X_test.float(), y_test)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Initialize the model and optimizer\n",
    "model = LeNet5()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "\n",
    "# Train the model\n",
    "num_epochs = 10\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    for batch_idx, (data, target) in enumerate(train_loader):\n",
    "        data, target = data.to(device), target.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, target)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # Evaluate the model\n",
    "    model.eval()\n",
    "    test_loss = 0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in test_loader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += criterion(output, target).item()\n",
    "            pred = output.argmax(dim=1, keepdim=True)\n",
    "            correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    accuracy = 100.0 * correct / len(test_loader.dataset)\n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Test Loss: {test_loss:.4f}, Accuracy: {accuracy:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#save the model\n",
    "torch.save(model.state_dict(), 'lenet5.pth')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    " \n",
    "# Save model\n",
    "with open(\"iris-model.pickle\", \"wb\") as fp:\n",
    "    pickle.dump(model.state_dict(), fp)\n",
    "    \n",
    "# Create new model and load states\n",
    "newmodel = LeNet5()\n",
    "with open(\"iris-model.pickle\", \"rb\") as fp:\n",
    "    newmodel.load_state_dict(pickle.load(fp))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['conv1.weight', 'conv1.bias', 'conv2.weight', 'conv2.bias', 'fc1.weight', 'fc1.bias', 'fc2.weight', 'fc2.bias', 'fc3.weight', 'fc3.bias']\n",
      "(6, 1, 5, 5)\n",
      "(6,)\n",
      "(16, 6, 5, 5)\n",
      "(16,)\n",
      "(120, 784)\n",
      "(120,)\n",
      "(84, 120)\n",
      "(84,)\n",
      "(10, 84)\n",
      "(10,)\n"
     ]
    }
   ],
   "source": [
    "state_dict = model.state_dict()\n",
    "keys=list(state_dict.keys())\n",
    "print(keys)\n",
    "for key in keys:\n",
    "    split=key.split('.')\n",
    "    print(state_dict[key].cpu().numpy().shape)\n",
    "    if split[1]=='weight':\n",
    "        name=\"W_\"+split[0]+\".npy\"\n",
    "    else:\n",
    "        name=\"b_\"+split[0]+\".npy\"\n",
    "    if 'fc' in split[0] and 'weight' in split[1]:\n",
    "        np.save(name,state_dict[key].cpu().numpy().transpose())\n",
    "    else:\n",
    "        np.save(name,state_dict[key].cpu().numpy())\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
